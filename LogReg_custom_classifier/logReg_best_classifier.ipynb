{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "df_x=  pd.read_csv('C:/Users/bhara/Downloads/x_train.csv')\n",
    "df_y =  pd.read_csv('C:/Users/bhara/Downloads/y_train.csv')\n",
    "df_x_test =  pd.read_csv('C:/Users/bhara/Downloads/x_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  website_name                                               text\n",
      "0       amazon    oh forgot also mention weird color effect phone\n",
      "1       amazon                              one didnt work either\n",
      "2       amazon                                     waste 13 bucks\n",
      "3       amazon  product useless since enough charging current ...\n",
      "4       amazon      none three sizes sent headset would stay ears\n",
      "  website_name                                               text\n",
      "0       amazon                    recognizes phone storage device\n",
      "1       amazon          disappointing accessory good manufacturer\n",
      "2       amazon  one big drawback mp3 player buttons phones fro...\n",
      "3       amazon  particular model would work motorola q smartphone\n",
      "4       amazon  two seperated mere 5 ft started notice excessi...\n"
     ]
    }
   ],
   "source": [
    "#Data preprocessing\n",
    "#includes puncutations, stopwords, stemming, tokens\n",
    "import string\n",
    "string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree\n",
    "df_x['text']= df_x['text'].apply(lambda x:remove_punctuation(x))\n",
    "df_x_test['text']= df_x_test['text'].apply(lambda x:remove_punctuation(x))\n",
    "\n",
    "import re\n",
    "def tokenization(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return ' '.join(tokens)\n",
    "df_x['text'] = df_x['text'].apply(tokenization).tolist()\n",
    "df_x_test['text'] = df_x_test['text'].apply(tokenization).tolist()\n",
    "\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text, language='english'):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "df_x['text']= df_x['text'].apply(lambda x:remove_stopwords(x))\n",
    "df_x_test['text']= df_x_test['text'].apply(lambda x:remove_stopwords(x))\n",
    "\n",
    "\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "    return ''.join(stem_text)\n",
    "df_x['text']=df_x['text'].apply(lambda x: stemming(x))\n",
    "df_x_test['text']=df_x_test['text'].apply(lambda x: stemming(x))\n",
    "\n",
    "print(df_x.head())\n",
    "print(df_x_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "word_embeddings = pd.read_csv('C:/Users/bhara/Downloads/glove.6B.50d.txt.zip',\n",
    "                               header=None, sep=' ', index_col=0,\n",
    "                               nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
    "word_list = word_embeddings.index.values.tolist()\n",
    "glove = OrderedDict(zip(word_list, word_embeddings.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    words = sentence.split()\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in glove:\n",
    "            embeddings.append(glove[word])\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(50)\n",
    "    else:\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         oh forgot also mention weird color effect phone\n",
      "1                                   one didnt work either\n",
      "2                                          waste 13 bucks\n",
      "3       product useless since enough charging current ...\n",
      "4           none three sizes sent headset would stay ears\n",
      "                              ...                        \n",
      "2395                sweet potato fries good seasoned well\n",
      "2396                      could eat bruschetta day devine\n",
      "2397                                     ambience perfect\n",
      "2398    ordered duck rare pink tender inside nice char...\n",
      "2399                          service good company better\n",
      "Name: text, Length: 2400, dtype: object\n",
      "0                        recognizes phone storage device\n",
      "1              disappointing accessory good manufacturer\n",
      "2      one big drawback mp3 player buttons phones fro...\n",
      "3      particular model would work motorola q smartphone\n",
      "4      two seperated mere 5 ft started notice excessi...\n",
      "                             ...                        \n",
      "595                           everything fresh delicious\n",
      "596                         really really good rice time\n",
      "597                                 pretty awesome place\n",
      "598                           staff great ambiance great\n",
      "599                            patio seating comfortable\n",
      "Name: text, Length: 600, dtype: object\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2400, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input_text = df_x['text']\n",
    "XTest = df_x_test['text']\n",
    "Y = df_y['is_positive_sentiment'].values\n",
    "\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "print(x_input_text)\n",
    "print(XTest)\n",
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2400, 50])\n",
      "torch.Size([2400, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "X = np.array([get_sentence_embedding(sentence) for sentence in x_input_text])\n",
    "Xtestfull= np.array([get_sentence_embedding(sentence) for sentence in XTest])\n",
    "\n",
    "X_full = Variable(torch.from_numpy(X)).float()\n",
    "X_test_full = Variable(torch.from_numpy(Xtestfull)).float()\n",
    "Y_full = Variable(torch.from_numpy(Y)).float()\n",
    "print(X_full.shape)\n",
    "print(Y_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5969986600726843\n",
      "0.5916569711685181\n",
      "0.5897168273568153\n",
      "0.5869904026187956\n",
      "0.586969052157402\n",
      "0.5863290090252956\n",
      "0.5864091276526451\n",
      "0.5861536004278809\n",
      "0.5856131999247604\n",
      "0.5857553703305125\n",
      "[0.7458333373069763, 0.7458333373069763, 0.7833333611488342, 0.7124999761581421, 0.7666666507720947, 0.7166666388511658, 0.7666666507720947, 0.7333333492279053, 0.75, 0.7916666865348816]\n",
      "Loss function = BCEWithLogitsLoss()\n",
      "Optimizer = <class 'torch.optim.sgd.SGD'>\n",
      "Learning rate = 0.01\n",
      "___Average Accuracy =___  0.7512499988079071\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20000\n",
    "\n",
    "model = LogisticRegression(X_full.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train)\n",
    "        label = y_train.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1)).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "\n",
    "print(accuracy_list)\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(\"Loss function =\", criterion)\n",
    "print(\"Optimizer =\", type(optimizer))\n",
    "print(\"Learning rate =\", learning_rate)\n",
    "print(f\"___Average Accuracy =___ \", accuracy_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16576251903027295\n",
      "0.16500145874843\n",
      "0.16428970323577524\n",
      "0.1639622358109802\n",
      "0.16436567814409733\n",
      "0.1641754616783311\n",
      "0.16428335130289198\n",
      "0.164121681068372\n",
      "0.164037867520584\n",
      "0.1637636554158479\n",
      "[0.7875000238418579, 0.7749999761581421, 0.7583333253860474, 0.7416666746139526, 0.8041666746139526, 0.7416666746139526, 0.7916666865348816, 0.7250000238418579, 0.7541666626930237, 0.737500011920929]\n",
      "Average Accuracy = 0.7616666734218598\n",
      "Optimizer = Adagrad\n",
      "Loss function = MSELoss()\n",
      "Learning rate = 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LogisticRegression1(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20000\n",
    "\n",
    "model = LogisticRegression1(X_full.shape[1])\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train)\n",
    "        label = y_train.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1)).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "\n",
    "print(accuracy_list)\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(\"Average Accuracy =\", accuracy_avg)\n",
    "print(\"Optimizer =\", type(optimizer).__name__)\n",
    "print(\"Loss function =\", criterion)\n",
    "print(\"Learning rate =\", learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5007791635692119\n",
      "0.4970045853048563\n",
      "0.4964164666707317\n",
      "0.4984847950752824\n",
      "0.4988835889342427\n",
      "0.4989423642463982\n",
      "0.498972539231394\n",
      "0.49879671789053825\n",
      "0.49915242947687705\n",
      "0.49974344847664237\n",
      "[0.7333333492279053, 0.762499988079071, 0.7666666507720947, 0.8541666865348816, 0.800000011920929, 0.800000011920929, 0.8083333373069763, 0.7958333492279053, 0.824999988079071, 0.8458333611488342]\n",
      "Average Accuracy = 0.7991666734218598\n",
      "Optimizer = Adam\n",
      "Loss function = BCEWithLogitsLoss()\n",
      "Learning rate = 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LogisticRegression2(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.tanh(out)\n",
    "        return out\n",
    "\n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20000\n",
    "\n",
    "model = LogisticRegression2(X_full.shape[1])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train)\n",
    "        label = y_train.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1)).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "\n",
    "print(accuracy_list)\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(\"Average Accuracy =\", accuracy_avg)\n",
    "print(\"Optimizer =\", type(optimizer).__name__)\n",
    "print(\"Loss function =\", criterion)\n",
    "print(\"Learning rate =\", learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16145604092478752\n",
      "0.15910177809409798\n",
      "0.15857169404005012\n",
      "0.15834232837017626\n",
      "0.15851219315871595\n",
      "0.15817555931508542\n",
      "0.15790892696614775\n",
      "0.1575668599354103\n",
      "0.1577632402341399\n",
      "0.15759509172722697\n",
      "[0.7791666388511658, 0.75, 0.7666666507720947, 0.7791666388511658, 0.7875000238418579, 0.762499988079071, 0.7666666507720947, 0.7166666388511658, 0.7749999761581421, 0.75]\n",
      "Average Accuracy = 0.7633333206176758\n",
      "Optimizer = Adagrad\n",
      "Loss function = MSELoss()\n",
      "Learning rate = 0.01\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LogisticRegression3(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.01\n",
    "num_epochs = 20000\n",
    "\n",
    "model = LogisticRegression3(X_full.shape[1])\n",
    "\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train)\n",
    "        label = y_train.view(-1, 1)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1)).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "\n",
    "print(accuracy_list)\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(\"Average Accuracy =\", accuracy_avg)\n",
    "print(\"Optimizer =\", type(optimizer).__name__)\n",
    "print(\"Loss function =\", criterion)\n",
    "print(\"Learning rate =\", learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48750409483909607\n",
      "0.36089479222893717\n",
      "0.27142167969296377\n",
      "0.21422663086559623\n",
      "0.17557524045836181\n",
      "0.14833087183069438\n",
      "0.12837809135937797\n",
      "0.11315416806115536\n",
      "0.10115906651209419\n",
      "0.09148731831647455\n",
      "[0.7749999761581421, 0.7708333134651184, 0.8166666626930237, 0.8916666507720947, 0.9541666507720947, 0.9708333611488342, 0.987500011920929, 0.9958333373069763, 0.9958333373069763, 0.9916666746139526]\n",
      "Average Accuracy = 0.9149999976158142\n",
      "Optimizer = Adam\n",
      "Loss function = BCEWithLogitsLoss()\n",
      "Learning rate = 0.001\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class CustomNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_size, 64)\n",
    "        self.linear2 = nn.Linear(64, 32)\n",
    "        self.linear3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.linear1(x))\n",
    "        out = F.relu(self.linear2(out))\n",
    "        out = self.linear3(out)\n",
    "        return out\n",
    "    def predict_probabilities(self, x):\n",
    "        out = self.forward(x)\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "\n",
    "model = CustomNeuralNet(X_full.shape[1])\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n",
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train.float())\n",
    "        label = y_train.view(-1, 1).float()\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test.float())\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1).float()).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "\n",
    "print(accuracy_list)\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(\"Average Accuracy =\", accuracy_avg)\n",
    "print(\"Optimizer =\", type(optimizer).__name__)\n",
    "print(\"Loss function =\", criterion)\n",
    "print(\"Learning rate =\", learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of y_prob.txt= 600\n"
     ]
    }
   ],
   "source": [
    "pred_probs = model.predict_probabilities(X_test_full.float())\n",
    "pred_probs = pred_probs.detach().numpy()\n",
    "path = 'C:/Users/bhara/OneDrive - scu.edu/Code Projects/NLP/yprob_test.txt'\n",
    "np.savetxt(path, np.asarray(pred_probs),fmt='%.6f')\n",
    "print(\"length of y_prob.txt=\",len(np.loadtxt(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a0a7811f90>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(num_epochs * folds), loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
