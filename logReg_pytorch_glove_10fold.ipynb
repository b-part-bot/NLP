{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Oh and I forgot to also mention the weird colo...\n",
      "1                            THAT one didn't work either.\n",
      "2                                      Waste of 13 bucks.\n",
      "3       Product is useless, since it does not have eno...\n",
      "4       None of the three sizes they sent with the hea...\n",
      "                              ...                        \n",
      "2395    The sweet potato fries were very good and seas...\n",
      "2396    I could eat their bruschetta all day it is dev...\n",
      "2397                                 Ambience is perfect.\n",
      "2398    We ordered the duck rare and it was pink and t...\n",
      "2399         Service was good and the company was better!\n",
      "Name: text, Length: 2400, dtype: object\n",
      "0      It only recognizes the Phone as its storage de...\n",
      "1      Disappointing accessory from a good manufacturer.\n",
      "2      The one big drawback of the MP3 player is that...\n",
      "3      This particular model would not work with my M...\n",
      "4      If the two were seperated by a mere 5+ ft I st...\n",
      "                             ...                        \n",
      "595                  Everything was fresh and delicious!\n",
      "596            - Really, really good rice, all the time.\n",
      "597                                Pretty awesome place.\n",
      "598          The staff are great, the ambiance is great.\n",
      "599              The patio seating was very comfortable.\n",
      "Name: text, Length: 600, dtype: object\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2400, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "df_x=  pd.read_csv('C:/Users/bhara/Downloads/x_train.csv')\n",
    "df_y =  pd.read_csv('C:/Users/bhara/Downloads/y_train.csv')\n",
    "df_x_test =  pd.read_csv('C:/Users/bhara/Downloads/x_test.csv')\n",
    "x_input_text = df_x['text']\n",
    "XTest = df_x_test['text']\n",
    "Y = df_y['is_positive_sentiment'].values\n",
    "\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "print(x_input_text)\n",
    "print(XTest)\n",
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "word_embeddings = pd.read_csv('C:/Users/bhara/Downloads/glove.6B.50d.txt.zip',\n",
    "                               header=None, sep=' ', index_col=0,\n",
    "                               nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
    "word_list = word_embeddings.index.values.tolist()\n",
    "glove = OrderedDict(zip(word_list, word_embeddings.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    words = sentence.split()\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in glove:\n",
    "            embeddings.append(glove[word])\n",
    "    if len(embeddings) == 0:\n",
    "        return np.zeros(50)\n",
    "    else:\n",
    "        return np.mean(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2400, 50])\n",
      "torch.Size([2400, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "X = np.array([get_sentence_embedding(sentence) for sentence in x_input_text])\n",
    "X_full = Variable(torch.from_numpy(X)).float()\n",
    "Y_full = Variable(torch.from_numpy(Y)).float()\n",
    "print(X_full.shape)\n",
    "print(Y_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.sigmoid(self.linear(x))\n",
    "    \n",
    "loss_func=[]\n",
    "accuracy_list = []\n",
    "folds = 10\n",
    "learning_rate = 0.2\n",
    "num_epochs = 20000\n",
    "\n",
    "model = LogisticRegression(X_full.shape[1])\n",
    "criterion = torch.nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters())    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5776, grad_fn=<DivBackward0>)\n",
      "tensor(0.5795, grad_fn=<DivBackward0>)\n",
      "tensor(0.5800, grad_fn=<DivBackward0>)\n",
      "tensor(0.5793, grad_fn=<DivBackward0>)\n",
      "tensor(0.5778, grad_fn=<DivBackward0>)\n",
      "tensor(0.5779, grad_fn=<DivBackward0>)\n",
      "tensor(0.5779, grad_fn=<DivBackward0>)\n",
      "tensor(0.5780, grad_fn=<DivBackward0>)\n",
      "tensor(0.5780, grad_fn=<DivBackward0>)\n",
      "tensor(0.5780, grad_fn=<DivBackward0>)\n",
      "[0.6583333611488342, 0.7083333134651184, 0.699999988079071, 0.7083333134651184, 0.6541666388511658, 0.6958333253860474, 0.6625000238418579, 0.7291666865348816, 0.6708333492279053, 0.6333333253860474]\n",
      "Average Accuracy =  0.6820833325386048\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index_val, test_index_val) in enumerate(kf.split(X_full)):\n",
    "    X_train, X_test = X_full[train_index_val], X_full[test_index_val]\n",
    "    y_train, y_test = Y_full[train_index_val], Y_full[test_index_val]\n",
    "    \n",
    "    for iteration in range(num_epochs):\n",
    "        output = model(X_train)\n",
    "        label = y_train.view(-1, 1) \n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss_func.append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test)\n",
    "        ypred = (output >= 0.5).float()\n",
    "        accuracy = (ypred == y_test.view(-1, 1)).float().mean().item()\n",
    "        accuracy_list.append(accuracy)\n",
    "    print(sum(loss_func)/len(loss_func))\n",
    "print(accuracy_list)\n",
    "\n",
    "accuracy_avg = sum(accuracy_list) / folds\n",
    "\n",
    "print(f\"Average Accuracy = \", accuracy_avg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
